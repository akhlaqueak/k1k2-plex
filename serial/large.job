#!/bin/bash
# normal command for interactive session: srun --ntasks=2 --cpus-per-task=1 --mem-per-cpu=64000 --time=12:00:00 --partition=pascalnodes --job-name=GG --gres=gpu:1 --pty /bin/bash
#SBATCH --share
#SBATCH --partition=medium
#
# Name your job to make it easier for you to track
#
#SBATCH --job-name=large
#
# Set your error and output files
#
#SBATCH --error=large.err
#SBATCH --output=large.out
#SBATCH --ntasks=48
#SBATCH --cpus-per-task=1
# Tell the scheduler only need 10 minutes
#
#SBATCH --time=6:00:00
#SBATCH --mem-per-cpu=10000
#
# Set your email address and request notification when you job is complete or if it fails
#
#SBATCH --mail-type=END
#SBATCH --mail-user=akhlaque.ak@gmail.com
module load Valgrind
alias python=python3

sr=1



./kplex -g ../datasets/webbase-2001.bin -k1 2 -k2 2 -q 300 -sr $sr >> large.out
sr=$((sr+1))
./kplex -g ../datasets/webbase-2001.bin -k1 3 -k2 3 -q 500 -sr $sr >> large.out
sr=$((sr+1))

./kplex -g ../datasets/clue-web.bin -k1 2 -k2 2 -q 10 -sr $sr >> large.out
sr=$((sr+1))
./kplex -g ../datasets/clue-web.bin -k1 3 -k2 3 -q 20 -sr $sr >> large.out
sr=$((sr+1))

./kplex -g ../datasets/it-2004.bin -k1 2 -k2 2 -q 1000 -sr $sr >> large.out
sr=$((sr+1))
./kplex -g ../datasets/it-2004.bin -k1 3 -k2 3 -q 3000 -sr $sr >> large.out
sr=$((sr+1))

./kplex -g ../datasets/arabic-2005.bin -k1 2 -k2 2 -q 1000 -sr $sr >> large.out
sr=$((sr+1))
./kplex -g ../datasets/arabic-2005.bin -k1 3 -k2 3 -q 3000 -sr $sr >> large.out
sr=$((sr+1))

./kplex -g ../datasets/uk-2005.bin -k1 2 -k2 2 -q 200 -sr $sr >> large.out
sr=$((sr+1))
./kplex -g ../datasets/uk-2005.bin -k1 3 -k2 3 -q 400 -sr $sr >> large.out
sr=$((sr+1))
wait
