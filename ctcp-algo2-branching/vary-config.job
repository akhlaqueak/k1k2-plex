#!/bin/bash
# normal command for interactive session: srun --ntasks=2 --cpus-per-task=1 --mem-per-cpu=64000 --time=12:00:00 --partition=pascalnodes --job-name=GG --gres=gpu:1 --pty /bin/bash
#SBATCH --share
#SBATCH --partition=medium
#
# Name your job to make it easier for you to track
#
#SBATCH --job-name=varyconfig
#
# Set your error and output files
#
#SBATCH --error=varyconfig.err
#SBATCH --output=varyconfig.out
#SBATCH --ntasks=1
# Tell the scheduler only need 10 minutes
#
#SBATCH --time=25:00:00
#SBATCH --mem-per-cpu=100000
#
# Set your email address and request notification when you job is complete or if it fails
#
#SBATCH --mail-type=END
#SBATCH --mail-user=akhlaque.ak@gmail.com
module load Valgrind
alias python=python3


# ds='bitcoin.txt'
# k1s='2 3 4 5'
# k2s='2 3 4 5'
# qs='8 9 10 11 12'
# fk1=3
# fk2=3
# rm $ds.res

# for k2 in $k2s; do
#     ./kplex -g ../datasets/$ds -k1 $fk1 -k2 $k2 -q 10 >> $ds.res 
# done

# for k1 in $k1s; do
#     ./kplex -g ../datasets/$ds -k1 $k1 -k2 $fk2 -q 10 >> $ds.res
# done

# for q in $qs; do
#     ./kplex -g ../datasets/$ds -k1 $fk1 -k2 $fk2 -q $q >> $ds.res
# done

echo "Done with bitcoin"

ds='epinions.txt'
k1s='2 3 4 5'
k2s='2 3 4 5'
qs='12 13 14 15 16 17 18'
fk1=2
fk2=2
fq=15
# rm $ds.res

# for k2 in $k2s; do
#     ./kplex -g ../datasets/$ds -k1 $fk1 -k2 $k2 -q $fq >> $ds.res 
# done

# for k1 in $k1s; do
#     ./kplex -g ../datasets/$ds -k1 $k1 -k2 $fk2 -q $fq >> $ds.res
# done

for q in $qs; do
    ./kplex -g ../datasets/$ds -k1 $fk1 -k2 $fk2 -q $q >> $ds.res
done
echo "Done with epinions"

ds='wiki-vote.txt'
k1s='2 3 4 5'
k2s='2 3 4 5'
qs='8 9 10 11 12'
fk1=3
fk2=3
fq=15
rm $ds.res

for k2 in $k2s; do
    ./kplex -g ../datasets/$ds -k1 $fk1 -k2 $k2 -q $fq >> $ds.res 
done

for k1 in $k1s; do
    ./kplex -g ../datasets/$ds -k1 $k1 -k2 $fk2 -q $fq >> $ds.res
done

for q in $qs; do
    ./kplex -g ../datasets/$ds -k1 $fk1 -k2 $fk2 -q $q >> $ds.res
done
echo "Done with wiki-vote"

ds='mathoverflow.txt'
k1s='2 3 4 5'
k2s='2 3 4 5'
qs='10 11 12 13 14'
fk1=3
fk2=3
fq=15

rm $ds.res

for k2 in $k2s; do
    ./kplex -g ../datasets/$ds -k1 $fk1 -k2 $k2 -q 10 >> $ds.res 
done

for k1 in $k1s; do
    ./kplex -g ../datasets/$ds -k1 $k1 -k2 $fk2 -q 10 >> $ds.res
done

for q in $qs; do
    ./kplex -g ../datasets/$ds -k1 $fk1 -k2 $fk2 -q $q >> $ds.res
done
echo "Done with mathoverflow"
