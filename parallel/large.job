#!/bin/bash
# normal command for interactive session: srun --ntasks=2 --cpus-per-task=1 --mem-per-cpu=64000 --time=12:00:00 --partition=pascalnodes --job-name=GG --gres=gpu:1 --pty /bin/bash
#SBATCH --share
#SBATCH --partition=medium
#
# Name your job to make it easier for you to track
#
#SBATCH --job-name=varyt
#
# Set your error and output files
#
#SBATCH --error=termvaryt.err
#SBATCH --output=termvaryt.out
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=48
# Tell the scheduler only need 10 minutes
#
#SBATCH --time=10:00:00
#SBATCH --mem-per-cpu=10000
#
# Set your email address and request notification when you job is complete or if it fails
#
#SBATCH --mail-type=END
#SBATCH --mail-user=akhlaque.ak@gmail.com
module load Valgrind
alias python=python3

export OMP_NUM_THREADS=32

simulation(){
echo $1
./kplex -g ../datasets/webbase-2001.bin -k1 2 -k2 2 -q 300 -t $1 >> varyt.out
./kplex -g ../datasets/webbase-2001.bin -k1 3 -k2 3 -q 500 -t $1 >> varyt.out

./kplex -g ../datasets/clue-web.bin -k1 2 -k2 2 -q 10 -t $1 >> varyt.out
./kplex -g ../datasets/clue-web.bin -k1 3 -k2 3 -q 20 -t $1 >> varyt.out

./kplex -g ../datasets/it-2004.bin -k1 2 -k2 2 -q 1000 -t $1 >> varyt.out
./kplex -g ../datasets/it-2004.bin -k1 3 -k2 3 -q 3000 -t $1 >> varyt.out

./kplex -g ../datasets/arabic-2005.bin -k1 2 -k2 2 -q 1000 -t $1 >> varyt.out
./kplex -g ../datasets/arabic-2005.bin -k1 3 -k2 3 -q 3000 -t $1 >> varyt.out

./kplex -g ../datasets/uk-2005.bin -k1 2 -k2 2 -q 200 -t $1 >> varyt.out
./kplex -g ../datasets/uk-2005.bin -k1 3 -k2 3 -q 400 -t $1 >> varyt.out

}

th='1 10 100 1000 10000 20000 50000 100000'
th=($th)
for i in "${!th[@]}"
do
     simulation ${th[i]}
done
